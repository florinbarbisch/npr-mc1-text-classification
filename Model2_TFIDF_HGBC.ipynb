{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 30%; float: right; margin: 10px; margin-right: 5%;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/FHNW_Logo.svg/2560px-FHNW_Logo.svg.png\" width=\"500\" style=\"float: left; filter: invert(50%);\"/>\n",
    "</div>\n",
    "\n",
    "<h1 style=\"text-align: left; margin-top: 10px; float: left; width: 60%;\">\n",
    "    npr Mini-Challenge 1: <br>TFIDF-HGBC\n",
    "</h1>\n",
    "\n",
    "<p style=\"clear: both; text-align: left;\">\n",
    "    Bearbeitet durch Florin Barbisch, Gabriel Torres Gamez und Jan Zwicky im HS 2023.\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellerklärung\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed euismod, nisl quis tincidunt aliquam, nunc nisl ultricies nunc, sit amet ultricies nisl ante nec leo. Donec vitae ex euismod, tincidunt nisl quis, gravida nisl. Sed vitae quam vitae nisl tincidunt lacinia. Nullam et semper nisl, sed rutrum ipsum. Donec ac odio nec dolor ultricies aliquam. Sed id nisl at nisi ultricies ultrices. Curabitur sed neque eget tortor vulputate imperdiet. Sed vitae dui nec justo aliquam ultrices. Sed id nunc euismod, ultricies velit nec, aliquam urna. Sed eget semper eros. Sed et nisl at magna ultricies lobortis. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Sed vel massa auctor, aliquet libero et, aliquet odio. Nulla facilisi. Sed sit amet dolor vel diam tincidunt aliquet. Donec sed tortor eget sapien gravida aliquet."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements, Imports und Einstellungen\n",
    "Hier werden die benötigten Python-Pakete importiert und die Einstellungen für die Plots\n",
    "vorgenommen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.10.13 (main, Aug 24 2023, 12:59:26) [Clang 15.0.0 (clang-1500.0.40.1)]\n",
      "PyTorch Version: 2.0.1\n",
      "Numpy Version: 1.23.5\n",
      "Scipy Version: 1.9.3\n",
      "Pandas Version: 2.1.1\n",
      "Matplotlib Version: 3.6.3\n",
      "Sklearn Version: 1.3.1\n",
      "Seaborn Version: 0.12.2\n"
     ]
    }
   ],
   "source": [
    "# All Imports\n",
    "import sys\n",
    "import html\n",
    "import scipy\n",
    "import torch\n",
    "import sklearn\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Versions of the packages used\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Numpy Version: {np.__version__}\")\n",
    "print(f\"Scipy Version: {scipy.__version__}\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"Matplotlib Version: {plt.matplotlib.__version__}\")\n",
    "print(f\"Sklearn Version: {sklearn.__version__}\")\n",
    "print(f\"Seaborn Version: {sns.__version__}\")\n",
    "\n",
    "# Warnings Settings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Numpy Settings\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Matplotlib Settings\n",
    "plt.rcParams[\"figure.figsize\"] = (24, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Hier werden Funktionen und Klassen definiert, die bei den Modellen verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics, shortcuts, constants, etc.\n",
    "class Pipeline:\n",
    "    \"\"\"Pipeline for customizable text classification model.\"\"\"\n",
    "\n",
    "    def __init__(self, vectorizer, classifier, reducer=None) -> None:\n",
    "        self.vectorizer = vectorizer\n",
    "        self.classifier = classifier\n",
    "        self.reducer = reducer\n",
    "\n",
    "    def fit(self, features, labels) -> \"Pipeline\":\n",
    "        \"\"\"\n",
    "        Fit the model to the given training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        features : list of str\n",
    "            Training data features.\n",
    "        labels : np.ndarray or pandas.Series\n",
    "            Training data labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "            The fitted model.\n",
    "        \"\"\"\n",
    "        self.vectorizer.fit(features)\n",
    "        transformed_features = self.vectorizer.transform(features).toarray()\n",
    "        if self.reducer:\n",
    "            self.reducer.fit(transformed_features)\n",
    "            transformed_features = self.reducer.transform(transformed_features)\n",
    "        self.classifier.fit(transformed_features, labels)\n",
    "        return self\n",
    "\n",
    "    def predict(self, features) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict labels for the given features.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        features : list of str\n",
    "            Features to predict labels for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Predicted labels for the given features.\n",
    "        \"\"\"\n",
    "        transformed_features = self.vectorizer.transform(features).toarray()\n",
    "        if self.reducer:\n",
    "            transformed_features = self.reducer.transform(transformed_features)\n",
    "        return self.classifier.predict(transformed_features)\n",
    "\n",
    "    def score(self, features, labels, metric=\"acc\") -> np.float64:\n",
    "        \"\"\"\n",
    "        Score the model on the given features and labels.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        features : list of str\n",
    "            Features to score the model on.\n",
    "        labels : np.ndarray or pandas.Series\n",
    "            Labels to score the model on.\n",
    "        metric : str, optional\n",
    "            Metric to use for scoring, by default \"acc\"\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.float64\n",
    "            Score of the model on the given features and labels.\n",
    "        \"\"\"\n",
    "        match metric:\n",
    "            case \"acc\":\n",
    "                return sklearn.metrics.accuracy_score(labels, self.predict(features))\n",
    "            case \"f1_macro\":\n",
    "                return sklearn.metrics.f1_score(labels, self.predict(features), average=\"macro\")\n",
    "            case _:\n",
    "                raise ValueError(f\"Unknown metric: {metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen des verarbeiteten Datensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/processed/train.csv', index_col=0)\n",
    "val = pd.read_csv('data/processed/val.csv', index_col=0)\n",
    "\n",
    "X_train = [html.unescape(tweet) for tweet in train[\"text\"]]\n",
    "X_val = [html.unescape(tweet) for tweet in val[\"text\"]]\n",
    "\n",
    "y_train = train[\"target\"]\n",
    "y_val = val[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikationsmodell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8786\n",
      "Train F1 Macro: 0.8727\n"
     ]
    }
   ],
   "source": [
    "# Define Pipeline\n",
    "TFIDF_HGBC = Pipeline(\n",
    "    vectorizer=TfidfVectorizer(max_features=1000),\n",
    "    reducer=None, # None, PCA, NMF, etc.\n",
    "    classifier=HistGradientBoostingClassifier(),\n",
    ")\n",
    "\n",
    "# Fit Pipeline\n",
    "TFIDF_HGBC.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Train Accuracy: {TFIDF_HGBC.score(X_train, y_train, metric='acc'):.4f}\")\n",
    "print(f\"Train F1 Macro: {TFIDF_HGBC.score(X_train, y_train, metric='f1_macro'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auswertung des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7756\n",
      "F1 Macro: 0.7650\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {TFIDF_HGBC.score(X_val, y_val.to_numpy(), metric='acc'):.4f}\")\n",
    "print(f\"F1 Macro: {TFIDF_HGBC.score(X_val, y_val, metric='f1_macro'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_test = pd.read_csv('data/processed/test.csv', index_col=\"id\", encoding=\"utf-8\")\n",
    "X_test = [html.unescape(tweet) for tweet in kaggle_test[\"text\"]]\n",
    "\n",
    "submisson = TFIDF_HGBC.predict(X_test)\n",
    "submisson = pd.DataFrame(submisson, index=kaggle_test.index, columns=[\"target\"])\n",
    "submisson.to_csv(\"data/submissions/TFIDF_HGBC.csv\", index=True, index_label=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "In der Evaluation beschreiben wir, welche Metrik verwendet wurde, wieso die Metrik für den Anwendungsfall passt und diskutieren die Ergebnisse der Experimente und einige Vorhersagen auf einzelnen Testsamples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erkenntnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
