{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 30%; float: right; margin: 10px; margin-right: 5%;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/FHNW_Logo.svg/2560px-FHNW_Logo.svg.png\" width=\"500\" style=\"float: left; filter: invert(50%);\"/>\n",
    "</div>\n",
    "\n",
    "<h1 style=\"text-align: left; margin-top: 10px; float: left; width: 60%;\">\n",
    "    npr Mini-Challenge 1: <br>BERTweet\n",
    "</h1>\n",
    "\n",
    "<p style=\"clear: both; text-align: left;\">\n",
    "    Bearbeitet durch Florin Barbisch, Gabriel Torres Gamez und Jan Zwicky im HS 2023.\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellerklärung\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed euismod, nisl quis tincidunt aliquam, nunc nisl ultricies nunc, sit amet ultricies nisl ante nec leo. Donec vitae ex euismod, tincidunt nisl quis, gravida nisl. Sed vitae quam vitae nisl tincidunt lacinia. Nullam et semper nisl, sed rutrum ipsum. Donec ac odio nec dolor ultricies aliquam. Sed id nisl at nisi ultricies ultrices. Curabitur sed neque eget tortor vulputate imperdiet. Sed vitae dui nec justo aliquam ultrices. Sed id nunc euismod, ultricies velit nec, aliquam urna. Sed eget semper eros. Sed et nisl at magna ultricies lobortis. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Sed vel massa auctor, aliquet libero et, aliquet odio. Nulla facilisi. Sed sit amet dolor vel diam tincidunt aliquet. Donec sed tortor eget sapien gravida aliquet."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements, Imports und Einstellungen\n",
    "Hier werden die benötigten Python-Pakete importiert und die Einstellungen für die Plots\n",
    "vorgenommen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\npr-mc1-text-classification\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]\n",
      "PyTorch Version: 2.0.1+cpu\n",
      "Numpy Version: 1.26.0\n",
      "Pandas Version: 2.1.1\n",
      "Matplotlib Version: 3.8.0\n",
      "Sklearn Version: 1.3.1\n",
      "Seaborn Version: 0.12.2\n",
      "Transformers Version: 4.34.0\n",
      "Datasets Version: 2.14.5\n",
      "Evalute Version: 0.4.0\n"
     ]
    }
   ],
   "source": [
    "# All Imports\n",
    "import sys\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "# Versions of the packages used\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Numpy Version: {np.__version__}\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"Matplotlib Version: {plt.matplotlib.__version__}\")\n",
    "print(f\"Sklearn Version: {sklearn.__version__}\")\n",
    "print(f\"Seaborn Version: {sns.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")\n",
    "print(f\"Datasets Version: {datasets.__version__}\")\n",
    "print(f\"Evalute Version: {evaluate.__version__}\")\n",
    "\n",
    "# Warnings Settings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Numpy Settings\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Matplotlib Settings\n",
    "plt.rcParams[\"figure.figsize\"] = (24, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Hier werden Funktionen definiert, die bei beiden Modellen verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics, shortcuts, constants, etc.\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen des Verarbeiteten Datensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"train\": pd.read_csv(\"./data/processed/train.csv\",index_col=\"id\"),\n",
    "    \"val\": pd.read_csv(\"./data/processed/val.csv\",index_col=\"id\"),\n",
    "    \"test\": pd.read_csv(\"./data/raw/test.csv\",index_col=\"id\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5988/5988 [00:01<00:00, 3615.17 examples/s]\n",
      "Map: 100%|██████████| 1497/1497 [00:00<00:00, 4066.70 examples/s]\n",
      "Map: 100%|██████████| 3263/3263 [00:00<00:00, 3544.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "for key in datasets.keys():\n",
    "    datasets[key] = Dataset.from_pandas(datasets[key].rename(columns={\"target\":\"label\"})) \\\n",
    "        .map(tokenize_function, batched=True)\n",
    "    \n",
    "train_dataset = datasets[\"train\"]\n",
    "val_dataset = datasets[\"val\"]\n",
    "test_dataset = datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikationsmodell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bertweet = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=bertweet,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auswertung des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "In der Evaluation beschreiben wir, welche Metrik verwendet wurde, wieso die Metrik für den Anwendungsfall passt und diskutieren die Ergebnisse der Experimente und einige Vorhersagen auf einzelnen Testsamples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erkenntnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
